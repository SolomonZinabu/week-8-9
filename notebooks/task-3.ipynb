{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the preprocessed fraud data and the trained Random Forest model\n",
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "model = joblib.load('../models/random_forest_fraud_model.pkl')\n",
    "\n",
    "# Drop non-numeric or irrelevant columns\n",
    "fraud_data_encoded = fraud_data.drop(columns=['signup_time', 'purchase_time', 'device_id', 'user_id'])\n",
    "\n",
    "# Convert categorical variables to one-hot encoding (must match training data format)\n",
    "fraud_data_encoded = pd.get_dummies(fraud_data_encoded, columns=['source', 'browser', 'sex'], drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = fraud_data_encoded.drop(columns=['class'])\n",
    "y = fraud_data_encoded['class']\n",
    "\n",
    "# Ensure SHAP can handle the data type\n",
    "X_sample = X.sample(100)  # SHAP handles smaller samples for faster computation\n",
    "\n",
    "# 1. SHAP Model Explainability\n",
    "## Initialize the SHAP explainer with the Random Forest model\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "## Generate SHAP values with additivity check disabled\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "# Inspect the structure of shap_values to ensure compatibility\n",
    "print(\"SHAP values structure:\", type(shap_values), len(shap_values), shap_values[1].shape)\n",
    "\n",
    "### SHAP Summary Plot\n",
    "# Use shap_values[1] if you are focusing on the fraud class (1)\n",
    "shap.summary_plot(shap_values[1], X_sample, plot_type=\"bar\", show=True)\n",
    "\n",
    "### SHAP Force Plot\n",
    "# Choose an instance to explain\n",
    "index = 10\n",
    "shap.initjs()  # Load JS for visualizations\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index], X_sample.iloc[index], matplotlib=True)\n",
    "\n",
    "### SHAP Dependence Plot\n",
    "# Select a feature to see its dependence with the prediction\n",
    "shap.dependence_plot(\"purchase_value\", shap_values[1], X_sample)\n",
    "\n",
    "# 2. LIME Model Explainability\n",
    "## Initialize LIME explainer\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(X.values, \n",
    "                                                        feature_names=X.columns,\n",
    "                                                        class_names=['Not Fraud', 'Fraud'],\n",
    "                                                        mode='classification')\n",
    "\n",
    "## Choose an instance to explain\n",
    "instance_index = 10\n",
    "instance = X.iloc[instance_index].values.reshape(1, -1)\n",
    "lime_exp = lime_explainer.explain_instance(X.iloc[instance_index].values, model.predict_proba)\n",
    "\n",
    "### LIME Explanation Plot\n",
    "lime_exp.show_in_notebook(show_table=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
